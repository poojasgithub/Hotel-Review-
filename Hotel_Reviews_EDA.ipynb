{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Group 1**\n",
    "# **Project 339 Hotel Reviews**\n",
    "## **Part 1 - EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 968.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from swifter) (1.5.3)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from swifter) (5.9.0)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from swifter) (2022.7.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from swifter) (4.64.1)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2022.11.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2022.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.6)\n",
      "Requirement already satisfied: locket in c:\\users\\dell\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->swifter) (1.12.0)\n",
      "Building wheels for collected packages: swifter\n",
      "  Building wheel for swifter (setup.py): started\n",
      "  Building wheel for swifter (setup.py): finished with status 'done'\n",
      "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16519 sha256=b5cb25f33e190f728f885d2be34ef36f9266e25c36b4a0a4c2fc1cd830953be3\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\43\\a7\\a3\\1194ca51c35c2a0c0041c97e4a9c1f0ed82a20cb3b1b08d610\n",
      "Successfully built swifter\n",
      "Installing collected packages: swifter\n",
      "Successfully installed swifter-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import cpu_count\n",
    "import re\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "import swifter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly\"\n",
    "\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "CPU_COUNT = cpu_count()\n",
    "with open('../Data/negations.json') as f:\n",
    "    negations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"hotel_reviews.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for missing/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *There are no null/missing values*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_string(tokens):\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_leading_trailing_space(text):\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_alphanumeric(text):\n",
    "    pattern = re.compile('\\w*\\d\\w* ')\n",
    "    result = pattern.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space_after_punctuation(text):\n",
    "    pattern = re.compile('(?<=[.,])(?=[^\\s])')\n",
    "    return pattern.sub(' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unknown(text):\n",
    "    text = re.sub('__Çî__otal', '', text)\n",
    "    text = re.sub('__Ç_é_', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spellings(text):\n",
    "    text = re.sub(r\"\\b(can't)\\b|\\B(can't)\\B\", r' \\1\\2 ', text)\n",
    "    text = re.sub(r\"(?<=\\s)ca n't(?=[\\s.,!?])\", \"can't\", text)\n",
    "    text = re.sub(r\"(?<=\\s)n't(?=[\\s.,!?])\", \"can't\", text)\n",
    "    text = re.sub(r'(?<=\\s)n(?=[\\s.,!?])', \"and\", text)\n",
    "    text = re.sub(r'(?<=\\s)u(?=[\\s.,!?])', \"you\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tokens_with_special_characters(tokens):\n",
    "    pattern = re.compile('[^a-zA-Z0-9]')\n",
    "    return [token for token in tokens if not pattern.search(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tokens_with_numbers(tokens):\n",
    "    pattern = re.compile('\\d')\n",
    "    return [token for token in tokens if not pattern.search(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemma_arr = []\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        lemma_arr.append(token.lemma_)\n",
    "    return lemma_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(tokens):\n",
    "    return [token.lower() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            result.append(token)\n",
    "        elif token in stop_words and token in negations:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews(text):\n",
    "    text = strip_leading_trailing_space(text)\n",
    "    text = remove_unknown(text)\n",
    "    text = add_space_after_punctuation(text)\n",
    "    text = correct_spellings(text)\n",
    "    text = remove_alphanumeric(text)\n",
    "    tokens = lemmatize(text)\n",
    "    tokens = to_lowercase(tokens)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = remove_tokens_with_special_characters(tokens)\n",
    "    tokens = remove_tokens_with_numbers(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing preprocessing techniques on reviews and saving them on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['Review']\\\n",
    ".swifter.set_npartitions(CPU_COUNT)\\\n",
    ".progress_bar(desc=\"Preprocessing Reviews\")\\\n",
    ".apply(preprocess_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving preprocessed reviews to disk...\")\n",
    "with open('preprocessed_reviews.pkl', 'wb') as f:\n",
    "    pickle.dump(reviews, f)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading preprocessed reviews from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/preprocessed_reviews.pkl', 'rb') as f:\n",
    "    reviews = pickle.load(f)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df[\"Rating\"].value_counts()\n",
    "fig = px.bar(data_frame=ratings, y=\"count\")\n",
    "fig.update_layout(xaxis_title=\"Rating\", yaxis_title=\"Count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference-\n",
    "- A large number of customers have given good 4-5 star ratings.\n",
    "- Few number of peoples have given low 1-2 star ratings.\n",
    "- This implies that most of the customers are nearly satisfied with their stay at the hotel.\n",
    "- And a large number of hotels are providing good and useful services to customers.\n",
    "- Few hotels are lacking a little bit in their quality of service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding out what words stand out in cleaned reviews using word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = reviews.apply(make_string).to_numpy()\n",
    "all_reviews = make_string(all_reviews)\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=1280, \n",
    "    height=720, \n",
    "    stopwords=stop_words, \n",
    "    max_words=100, \n",
    "    background_color=\"white\",\n",
    "    margin=3\n",
    ").generate(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150, figsize=(8,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Cleaned Reviews\", pad=15, weight=\"bold\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference-\n",
    "- From the word cloud it can be concluded that most of the reviews contain positve words, this means most of the reveiws about hotels are positive.\n",
    "- So, majority of hotels are of good standards and are providing good and useful services to customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigrams(token):\n",
    "    return list(ngrams(token, 2))\n",
    "\n",
    "def create_trigrams(token):\n",
    "    return list(ngrams(token, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams_frequency(ngrams, top_n=None):\n",
    "    ngram_pairs = []\n",
    "    for item in ngrams:\n",
    "        for pairs in item:\n",
    "            ngram_pairs.append(\" \".join(pairs))\n",
    "    ngrams_freq = Counter(ngram_pairs)\n",
    "    if top_n:\n",
    "        labels, counts = zip(*ngrams_freq.most_common(n=top_n))\n",
    "    else:\n",
    "        labels, counts = zip(*ngrams_freq.items())\n",
    "    return labels, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating n-grams from cleaned reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = reviews.apply(create_bigrams)\n",
    "trigrams = reviews.apply(create_trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Top Frequent N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_labels, bigram_counts = get_ngrams_frequency(bigrams, top_n)\n",
    "fig = px.bar(x=bigram_labels, y=bigram_counts)\n",
    "fig.update_layout(xaxis_title=\"Bigram\", yaxis_title=\"Count\", title=f\"Top {top_n} Bigrams\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_labels, trigram_counts = get_ngrams_frequency(trigrams, top_n)\n",
    "fig = px.bar(x=trigram_labels, y=trigram_counts)\n",
    "fig.update_layout(xaxis_title=\"Trigram\", yaxis_title=\"Count\", title=f\"Top {top_n} Trigrams\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference-\n",
    "- Top frequent bigrams and trigrams are positive sounding like **\"great location\"**, **\"clean room\"**, **\"staff freindly helpful\"**, **\"higly recommend hotel\"**, **\"flat screen tv\"**, **\"hotel staff friendly\"**, etc.\n",
    "- This means that most of the hotels are of good standard and provide good and useful services to customers. Resulting in most number of happy customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_strings = reviews.apply(make_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "scores = [analyzer.polarity_scores(review) for review in reviews_strings]\n",
    "\n",
    "result_dict = defaultdict(list)\n",
    "result_dict[\"Cleaned_Reviews\"] = reviews_strings\n",
    "for d in scores:\n",
    "  for key, value in d.items():\n",
    "    if key == \"compound\":\n",
    "      result_dict[\"Score\"].append(value)\n",
    "      if value > 0:\n",
    "          result_dict[\"Sentiment\"].append(\"Positive\")\n",
    "      elif value < 0:\n",
    "          result_dict[\"Sentiment\"].append(\"Negative\")\n",
    "      else:\n",
    "          result_dict[\"Sentiment\"].append(\"Neutral\")\n",
    "\n",
    "scores_df = pd.DataFrame(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaned reviews with their sentiment label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(dict(Reviews=reviews, Sentiment=scores_df['Sentiment'].apply(lambda s: 'Positive' if s == 'Neutral' else s)))\n",
    "final_df.to_pickle('processed_reviews_with_sentiment.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = scores_df[\"Sentiment\"].value_counts()\n",
    "fig = px.pie(\n",
    "    names=value_counts.index,\n",
    "    values=value_counts.values,\n",
    "    color_discrete_sequence=[\"#00CC96\", \"#636EFA\", \"#EF553B\"],\n",
    "    hole=0.5\n",
    ")\n",
    "fig.update_layout(legend={\"title\": \"Sentiment\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review count for each sentiment category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=value_counts.index, y=value_counts)\n",
    "fig.update_layout(xaxis_title=\"Sentiment\", yaxis_title=\"Count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference-\n",
    "- As speculated earlier from word clouds and n-grams, indeed majority of the reviews are positve after performing sentiment analysis.\n",
    "- Number of neutral reviews are insignificant hence, ignoring them for further steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Sentiment by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = scores_df.groupby([\"Rating\", \"Sentiment\"]).size().unstack().fillna(0)\n",
    "fig = go.Figure()\n",
    "for sentiment in rating_counts.columns:\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=sentiment,\n",
    "        x=rating_counts.index,\n",
    "        y=rating_counts[sentiment]))\n",
    "fig.update_layout(barmode=\"stack\")\n",
    "fig.update_layout(xaxis_title=\"Rating\", yaxis_title=\"Count\", legend={\"title\": \"Sentiment\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference-\n",
    "- With increase in rating, number of positive reviews also increases.\n",
    "- For 1 star rating there are nearly equal number negative and postive reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Since there are fewer neutral reviews, not taking them into account for subsequent actions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Postive and Negative Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Finding what words stand out for both sentiments by creating word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = scores_df[scores_df[\"Sentiment\"] == \"Positive\"]\n",
    "negative_reviews = scores_df[scores_df[\"Sentiment\"] == \"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_positive_reviews = make_string(positive_reviews[\"Cleaned_Reviews\"].to_numpy())\n",
    "merged_negative_reviews = make_string(negative_reviews[\"Cleaned_Reviews\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_wordcloud = WordCloud(width=1280, height=720, max_words=100, background_color=\"white\", margin=3).generate(merged_positive_reviews)\n",
    "negative_wordcloud = WordCloud(width=1280, height=720, max_words=100, background_color=\"white\", margin=3).generate(merged_negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12,7), dpi=250)\n",
    "axs[0].imshow(positive_wordcloud, interpolation=\"bilinear\")\n",
    "axs[0].set_title(\"Positive Reviews\", pad=15, weight=\"bold\")\n",
    "axs[1].imshow(negative_wordcloud, interpolation=\"bilinear\")\n",
    "axs[1].set_title(\"Negative Reviews\", pad=15, weight=\"bold\")\n",
    "for ax in axs:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "line = Line2D([0.5, 0.5], [0.25, 0.75], transform=fig.transFigure, figure=fig, color='black')\n",
    "fig.lines.extend([line])\n",
    "\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference-\n",
    "- **\"hotel\"** is the main topic in both positve and negative reviews. And indeed it should be like this.\n",
    "- In negative reviews **\"room\"** is another biggest topic. This indicates that people who wrote negative reviews had faced most of the problems in their rooms. This as well makes sense as hotels are used for temporary stay, rooms should be in good condition in hotels and if anything is not appropriate in a room, customers will not be happy.\n",
    "- In positive reviews there are many postive words like **\"clean room\"**, **\"excellent\"**, **\"fun\"**, **\"great location\"**, **\"great hotel\"**, etc.\n",
    "- In negative reviews there are mostly positive sounding words but still there are negative words like **\"bad\"**, **\"rude\"**, **\"small\"**, **\"noting\"**, etc., but overall they are still negative, this means some of the hotels are lacking a little bit in providing good and usefule services to customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
